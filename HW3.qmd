---
title: "HW3"
author: "Jiaqi"
format:
  html:
    embed-resources: true
    code-overflow: wrap
editor: visual
---

GitHub repositoryï¼š

## Problem 1 - Vision

a.  Download the SAS file VIX_D, and then read it into Stata. Then download another SAS file DEMO_D. Merge the two files to create a single dataset, using the SEQN variable for merging. Print total sample size, showing that it is now 6,980.

``` stata
. * Read the VIX_D & DEMO_D dataset.
. * Save it as a Stata dataset.
. log using hw3_p1.log, replace
-------------------------------------------------------------------------------------------------------
      name:  <unnamed>
       log:  /Users/jiaqizhu/Downloads/506/HW3/hw3_p1.log
  log type:  text
 opened on:   8 Oct 2023, 13:39:42

. import sasxport "VIX_D.xpt", clear

. save "VIX_D.dta", replace
file VIX_D.dta saved

. import sasxport "DEMO_D.xpt", clear

. save "DEMO_D.dta", replace
file DEMO_D.dta saved

. * Merging the datasets using the SEQN variable
. use "VIX_D.dta", clear

. merge 1:1 seqn using "DEMO_D.dta", keep(match) nogenerate

    Result                           # of obs.
    -----------------------------------------
    not matched                             0
    matched                             6,980  
    -----------------------------------------

. * Print total sample size, showing that it is now 6,980.
. count
  6,980
```

b.  Estimate the proportion of respondents within each 10-year age bracket who wear glasses/contact lenses for distance vision. Produce a nice table with the results.

We can see that the min. of age is 12 and the max. is 85, so we create age bracket 10-19, 20-29, ..., 80-89. First, based on viq240, we divide people into two category - "wear glasses or contacts" and "wear none".

``` stata
. * Creating Age Brackets
. sum ridageyr

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
    ridageyr |      6,980    37.87894    21.89424         12         85

. egen agegroup = cut(ridageyr), at(10(10)90) label

. gen wears_glasses_or_contacts = (viq240 == 1 | viq240 == 2 | viq240 == 3)

. * Tabulating the Proportions
. tab agegroup wears_glasses_or_contacts, row nofreq

           | wears_glasses_or_cont
           |         acts
  agegroup |         0          1 |     Total
-----------+----------------------+----------
       10- |     78.43      21.57 |    100.00 
       20- |     75.51      24.49 |    100.00 
       30- |     70.90      29.10 |    100.00 
       40- |     69.57      30.43 |    100.00 
       50- |     49.76      50.24 |    100.00 
       60- |     44.93      55.07 |    100.00 
       70- |     38.59      61.41 |    100.00 
       80- |     44.41      55.59 |    100.00 
-----------+----------------------+----------
     Total |     65.90      34.10 |    100.00 
```

And within the wears_glasses_or_contacts, we know there are three sub categories - "glasses", "contact" and "both", so we can make another table with more specific information.

``` stata
. * Modify labels for viq240 to include a category for non-users.
. label define viq240_label 1 "Glasses" 2 "Contacts" 3 "Both" 4 "None", replace

. replace viq240 = 4 if viq240 != 1 & viq240 != 2 & viq240 != 3
(4,600 real changes made)

. label values viq240 viq240_label

. tab agegroup viq240, row nofreq

           |      Which type? Glasses or contacts?
  agegroup |   Glasses   Contacts       Both       None |     Total
-----------+--------------------------------------------+----------
       10- |     14.05       7.07       0.45      78.43 |    100.00 
       20- |     14.30       8.91       1.27      75.51 |    100.00 
       30- |     19.68       7.70       1.71      70.90 |    100.00 
       40- |     25.52       3.80       1.10      69.57 |    100.00 
       50- |     46.43       3.80       0.00      49.76 |    100.00 
       60- |     52.50       2.27       0.30      44.93 |    100.00 
       70- |     60.77       0.64       0.00      38.59 |    100.00 
       80- |     55.59       0.00       0.00      44.41 |    100.00 
-----------+--------------------------------------------+----------
     Total |     27.92       5.49       0.69      65.90 |    100.00 
```

c.  Fit three logistic regression models predicting whether a respondent wears glasses/contact lenses for distance vision. Predictors: 1.age 2.age, race, gender 3.age, race, gender, Poverty Income ratio Produce a table presenting the estimated odds ratios for the coefficients in each model, along with the sample size for the model, the pseudo-R\^2, and AIC values.

``` stata
. * Model 1
. logit wears_glasses_or_contacts ridageyr

Iteration 0:   log likelihood = -4478.9233  
Iteration 1:   log likelihood = -4183.3681  
Iteration 2:   log likelihood =  -4181.457  
Iteration 3:   log likelihood = -4181.4567  

Logistic regression                             Number of obs     =      6,980
                                                LR chi2(1)        =     594.93
                                                Prob > chi2       =     0.0000
Log likelihood = -4181.4567                     Pseudo R2         =     0.0664

-------------------------------------------------------------------------------------------
wears_glasses_or_contacts |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
--------------------------+----------------------------------------------------------------
                 ridageyr |   .0284784   .0012043    23.65   0.000      .026118    .0308389
                    _cons |  -1.789714   .0561758   -31.86   0.000    -1.899816   -1.679611
-------------------------------------------------------------------------------------------

. estimates store m1

. local n1 = e(N)

. local pseudoR21 = e(r2_p)

. local ll1 = e(ll)

. local aic1 = -2*`ll1' + 2*1 

. outreg2 using results.doc, eform replace ctitle() addstat(Sample Size, e(N), Log Likelihood, `ll1', Pseudo R^2, e(r2_p), AIC, `aic1')

. * Model 2
. logit wears_glasses_or_contacts ridageyr ridreth1 riagendr

Iteration 0:   log likelihood = -4478.9233  
Iteration 1:   log likelihood = -4136.6769  
Iteration 2:   log likelihood = -4133.3559  
Iteration 3:   log likelihood = -4133.3541  
Iteration 4:   log likelihood = -4133.3541  

Logistic regression                             Number of obs     =      6,980
                                                LR chi2(3)        =     691.14
                                                Prob > chi2       =     0.0000
Log likelihood = -4133.3541                     Pseudo R2         =     0.0772

-------------------------------------------------------------------------------------------
wears_glasses_or_contacts |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
--------------------------+----------------------------------------------------------------
                 ridageyr |   .0286168   .0012192    23.47   0.000     .0262272    .0310065
                 ridreth1 |   .1351966    .023254     5.81   0.000     .0896196    .1807735
                 riagendr |   .4192284   .0536014     7.82   0.000     .3141715    .5242853
                    _cons |  -2.826326   .1234478   -22.89   0.000    -3.068279   -2.584373
-------------------------------------------------------------------------------------------

. estimates store m2

. local n2 = e(N)

. local pseudoR22 = e(r2_p)

. local ll2 = e(ll)

. local aic2 = -2*`ll2' + 2*3 

. outreg2 using results.doc, eform append ctitle() addstat(Sample Size, e(N), Log Likelihood, `ll2', Pseudo R^2, e(r2_p), AIC, `aic2')

. * Model 3
. logit wears_glasses_or_contacts ridageyr ridreth1 riagendr indfmpir

Iteration 0:   log likelihood = -4277.4096  
Iteration 1:   log likelihood = -3905.0737  
Iteration 2:   log likelihood = -3900.1884  
Iteration 3:   log likelihood = -3900.1829  
Iteration 4:   log likelihood = -3900.1829  

Logistic regression                             Number of obs     =      6,638
                                                LR chi2(4)        =     754.45
                                                Prob > chi2       =     0.0000
Log likelihood = -3900.1829                     Pseudo R2         =     0.0882

-------------------------------------------------------------------------------------------
wears_glasses_or_contacts |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
--------------------------+----------------------------------------------------------------
                 ridageyr |   .0276009    .001265    21.82   0.000     .0251215    .0300803
                 ridreth1 |   .0880404   .0245416     3.59   0.000     .0399398     .136141
                 riagendr |    .454698   .0552825     8.22   0.000     .3463463    .5630496
                 indfmpir |    .188783   .0173202    10.90   0.000      .154836    .2227299
                    _cons |  -3.174577   .1343728   -23.63   0.000    -3.437943   -2.911211
-------------------------------------------------------------------------------------------

. estimates store m3

. local n3 = e(N)

. local pseudoR23 = e(r2_p)

. local ll3 = e(ll)

. local aic3 = -2*`ll3' + 2*4  

. outreg2 using results.doc, eform append ctitle() addstat(Sample Size, e(N), Log Likelihood, `ll3', Pseudo R^2, e(r2_p), AIC, `aic3')
results.doc
dir : seeout
```

In this way, we obtained a nice table in results.doc.

![result](./table_result.jpeg)

Another way to produce such a table, without using outreg2, is in the following. But it's not nice-organized.

``` stata
. esttab m1 m2 m3, eform cells("b(fmt(3) star) se(fmt(3) par)") ///
>       stats(N ll r2_p AIC, fmt(2 3 3 2) labels("Sample Size" "Log Likelihood" "Pseudo R^2" "AIC")) //
> /
>       mtitle("Model 1" "Model 2" "Model 3") label

-------------------------------------------------------------------------------------------------------
> ----
                              (1)                          (2)                          (3)            
>     
                          Model 1                      Model 2                      Model 3            
>     
                                b              se            b              se            b            
>   se
-------------------------------------------------------------------------------------------------------
> ----
wears_glasses_or_c~s                                                                                   
>     
Age at Screening A~R        1.029***      (0.001)        1.029***      (0.001)        1.028***      (0.
> 001)
Race/Ethnicity - R~e                                     1.145***      (0.027)        1.092***      (0.
> 027)
Gender                                                   1.521***      (0.082)        1.576***      (0.
> 087)
Family PIR                                                                            1.208***      (0.
> 021)
-------------------------------------------------------------------------------------------------------
> ----
Sample Size               6980.00                      6980.00                      6638.00            
>     
Log Likelihood          -4181.457                    -4133.354                    -3900.183            
>     
Pseudo R^2                  0.066                        0.077                        0.088            
>     
AIC                                                                                                    
>     
-------------------------------------------------------------------------------------------------------
> ----
Exponentiated coefficients
```

d.  From the third model, discuss whether the odds of men and women being wears of glasess/contact differs. Test whether the proportion of wearers of glasses/contact differs between men and women.

``` stata
. logit wears_glasses_or_contacts ridageyr ridreth1 riagendr indfmpir

Iteration 0:   log likelihood = -4277.4096  
Iteration 1:   log likelihood = -3905.0737  
Iteration 2:   log likelihood = -3900.1884  
Iteration 3:   log likelihood = -3900.1829  
Iteration 4:   log likelihood = -3900.1829  

Logistic regression                             Number of obs     =      6,638
                                                LR chi2(4)        =     754.45
                                                Prob > chi2       =     0.0000
Log likelihood = -3900.1829                     Pseudo R2         =     0.0882

-------------------------------------------------------------------------------------------
wears_glasses_or_contacts |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
--------------------------+----------------------------------------------------------------
                 ridageyr |   .0276009    .001265    21.82   0.000     .0251215    .0300803
                 ridreth1 |   .0880404   .0245416     3.59   0.000     .0399398     .136141
                 riagendr |    .454698   .0552825     8.22   0.000     .3463463    .5630496
                 indfmpir |    .188783   .0173202    10.90   0.000      .154836    .2227299
                    _cons |  -3.174577   .1343728   -23.63   0.000    -3.437943   -2.911211
-------------------------------------------------------------------------------------------


. prtest wears_glasses_or_contacts, by(riagendr)

Two-sample test of proportions                     1: Number of obs =     3383
                                                   2: Number of obs =     3597
------------------------------------------------------------------------------
       Group |       Mean   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           1 |   .3012119   .0078878                      .2857521    .3166718
           2 |   .3783709   .0080864                      .3625218    .3942199
-------------+----------------------------------------------------------------
        diff |  -.0771589   .0112964                     -.0992994   -.0550185
             |  under Ho:   .0113532    -6.80   0.000
------------------------------------------------------------------------------
        diff = prop(1) - prop(2)                                  z =  -6.7962
    Ho: diff = 0

    Ha: diff < 0                 Ha: diff != 0                 Ha: diff > 0
 Pr(Z < z) = 0.0000         Pr(|Z| > |z|) = 0.0000          Pr(Z > z) = 1.0000
```

From the Logistic Regression Model, the coefficient for riagendr is statistically significant at 0.01 level( p \< 0.01), so the odds of wearing glasses/contact lenses for distance vision differs between men and women.

The coefficient for the riagendr is .454698, and **odds ratio** = exp(.454698) = 1.5757. Greater than 1 indicates that as the predictor increases 1, the odds of the outcome occurring increase 57.57%. This means for being a female compared a male, the odds of wearing glasses/contact increase by about 57.57%.

From the Proportions Test, the proportion of wearers of glasses/contact for female is .3783709, for male is .3012119. The p-value from the prtest command is below 0.01 significance level, so reject the null hypothesis and conclude that there's a statistically significant difference in the proportion of glasses/contact lens wearers between male and female.

## Problem 2 - Sakila

a.  Aside from English, what language is most common for films? Answer this with a single SQL query.

``` sql
SELECT l.name, COUNT(f.film_id) AS film_count
FROM film f
JOIN language l ON f.language_id = l.language_id
WHERE l.name <> 'English'
GROUP BY l.name
ORDER BY film_count DESC
LIMIT 1;
```

We didn't get any result. So it seems that English is the only language used in these films. To check our guess, we use the command:

``` sql
SELECT DISTINCT l.name 
FROM language l
JOIN film f ON f.language_id = l.language_id;

SELECT COUNT(DISTINCT language_id) AS unique_language_count
FROM film;
```

We get the output of "English" and "1". So English is the only language for these films in the table.

b.  What genre of movie is the most common in the data, and how many movies are of this genre?

```{r}
library(DBI)
library(RSQLite)
# Connect to the SQLite database
con <- dbConnect(RSQLite::SQLite(), "/Users/jiaqizhu/Downloads/sakila_master.db")
con
film_category <- dbGetQuery(con, "SELECT * FROM film_category")
category <- dbGetQuery(con, "SELECT * FROM category")
```

```{r}
# Count films per category
film_counts <- table(film_category$category_id)

# Get the most common genre ID and count
most_common_genre_id <- as.integer(names(film_counts)[which.max(film_counts)])
most_common_count <- max(film_counts)

# Get the genre name
most_common_genre_name <- subset(category, category_id == most_common_genre_id)$name

print(most_common_genre_name)
print(most_common_count)

# Disconnect
dbDisconnect(con)
```

``` sql
SELECT category.name, COUNT(film_id) AS film_count
FROM film_category
JOIN category ON film_category.category_id = category.category_id
GROUP BY category.name
ORDER BY film_count DESC
LIMIT 1;

Sports|74
```

c.  Identify which country or countries have exactly 9 customers. Answer this with a single SQL query.

``` sql
SELECT country, COUNT(customer_id) AS customer_count
FROM customer
JOIN address ON customer.address_id = address.address_id
JOIN city ON address.city_id = city.city_id
JOIN country ON city.country_id = country.country_id
GROUP BY country
HAVING customer_count = 9;

United Kingdom|9
```

## Problem 3 - US Records

```{r}
data <- read.csv("/Users/jiaqizhu/Downloads/506/HW3/us-500.csv")
```

a.  What proportion of email addresses are hosted at a domain with TLD ".net"?

```{r}
net_emails <- sum(grepl("@.*\\.net$", data$email))
prop_net <- net_emails / nrow(data)
prop_net
```

b.  What proportion of email addresses have at least one non alphanumeric character in them?

```{r}
non_alnum_emails <- sum(grepl("[^[:alnum:]@\\.]", data$email))
prop_non_alnum <- non_alnum_emails / nrow(data)
prop_non_alnum
```

c.  What is the most common area code amongst all phone numbers?

```{r}
all_phones <- c(data$phone1, data$phone2)
area_codes <- gsub("^(\\d{3})-.*", "\\1", all_phones)
most_common_area_code <- as.integer(names(sort(table(area_codes), decreasing=TRUE)[1]))
most_common_area_code
```

d.  Produce a histogram of the log of the apartment numbers for all addresses.

```{r}
#data$sub_address <- gsub("^\\d+", "", data$address)
#apt_numbers <- as.numeric(gsub("\\D", "", data$sub_address))
#apt_numbers_notna <- as.numeric(apt_numbers[!is.na(apt_numbers)])
apartments <- as.numeric(gsub(".*#(\\d+)$", "\\1", data$address))
apartment_numbers <- apartments[!is.na(apartments)]
apartment_numbers
hist(log(apartment_numbers))
```

e.  Benford's law is an observation about the distribution of the leading digit of real numerical data. Examine whether the apartment numbers appear to follow Benford's law. Do you think the apartment numbers would pass as real data?

According to Benford's Law, the distribution of leading digits is expected to be:
1: 30.1%
2: 17.6%
3: 12.5%
4: 9.7%
5: 7.9%
6: 6.7%
7: 5.8%
8: 5.1%
9: 4.6%

```{r}
benford_first <- c(0.301, 0.176, 0.125, 0.097, 0.079, 0.067, 0.058, 0.051, 0.046)

leading_digits <- as.integer(substr(apartment_numbers, 1, 1))
# Calculate observed frequencies
observed_first <- table(leading_digits) / length(leading_digits)
observed_first
# Chi-squared test for first digit
expected_first <- benford_first * length(leading_digits)
chi_first <- chisq.test(as.vector(table(leading_digits)), p = benford_first)
print(chi_first)
```
The Chi-squared test gives a p-value, which tells the probability that the observed frequencies are from a distribution that matches the expected frequencies. A low p-value < 0.05 suggests that the data does not conform to the expected distribution. So the first digit of a sequence of numbers doesn't follows Benfordâ€™s Law: I don't think the apartment numbers would pass as real data. The data might be synthetic or manipulated.

f.  Repeat your analysis of Benford's law on the last digit of the street number.

```{r}
st_number <- sub("^(\\d+).*", "\\1", data$address)
st_number <- as.integer(st_number)
last_digits <- as.integer(substr(st_number, nchar(st_number), nchar(st_number)))

observed_last <- table(last_digits) / length(last_digits)
observed_last

# Chi-squared test for last digit (uniform distribution)
expected_last <- rep(0.1, 10) * length(last_digits)
chi_last <- chisq.test(as.vector(table(last_digits)), p = rep(0.1, 10))

print(chi_last)
```

The last digit of numbers should be uniformly distributed if it follows Benford's Law. That means each of the digits (0 through 9) should appear about 10% of the time.

Based on the results from the above analyses, we draw conclusions about there isn't enough evidence to say the last digit doesn't follow the expected distribution.
